{
  "name": "bedrock",
  "type": "bedrock",
  "displayName": "AWS Bedrock",
  "description": "AWS Bedrock provider for LLM inference",
  "region": "us-east-1",
  "defaultSettings": {
    "maxTokens": 1024,
    "temperature": 0.7,
    "topP": 1
  },
  "capabilities": {
    "streaming": true,
    "inferenceTypes": {
      "onDemand": true,
      "provisioned": false
    },
    "modalities": [
      "text-to-text",
      "text-to-image",
      "embedding"
    ]
  },
  "vendors": [
    "amazon",
    "anthropic",
    "meta",
    "cohere",
    "mistral",
    "ai21",
    "stability"
  ],
  "settings": {
    "maxConcurrentRequests": 100,
    "requestTimeout": 30000,
    "retryConfig": {
      "maxAttempts": 3,
      "baseDelay": 1000
    }
  }
}