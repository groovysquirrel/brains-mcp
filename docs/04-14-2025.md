# BRAINS Operating System Development Log

## Initial Instructions

We are building a broad range AI node system (BRAINS) and an operating system to manage it. The project is described here in `./README.md`

We have a functional websocket backend and a functional xterm terminal that connects to it. The frontend terminal is described here in `./packages/frontend/components/terminal` with the websocket handlers in `./packages/frontend/src/lib/websocket.ts`

Currently, the backend websocket connect is established by the handler in `/packages/brainsOS/handlers/websocket/controller/default.ts`, which leverages the `chat.ts` LLM gateway handler in `/packages/brainsOS/handlers/llm-gateway/chat.ts`

## BACKEND TODO FOR TODAY

### PROJECT 1

- [x] Turn our controller into a singleton implementation, so that we can share the same controller instance across multiple handlers. We want to modularize and seperate areas of concern, similar to how `chat.ts` loads the module in `/packages/brainsOS/modules/llm-gateway/gateway.ts`. For the controller, we want to move the logic from `/packages/brainsOS/handlers/websocket/controller/default.ts` into `/packages/brainsOS/modules/controller/BrainController.ts` (previously ModelController.ts)

    **Completed:**
    - Created `BrainController` as a singleton with proper initialization
    - Implemented dependency injection for repository and gateway
    - Added configurable brain name with default fallback
    - Integrated with LLM Gateway for chat processing
    - Added conversation state management
    - Implemented MCP prompt integration

- [x] Our controller will need a respository of brains (previously called models), so we will need to create a `BrainRepository.ts` module in `/packages/brainsOS/modules/controller/src/repositories/BrainRepository.ts`, with a similar file structure to `/packages/brainsOS/modules/llm-gateway/`. We will put types in `/packages/brainsOS/modules/controller/src/types` and utils in `/packages/brainsOS/modules/controller/src/utils`. The configuration will be local for now, and put into `/packages/brainsOS/modules/controller/src/config/defaults.json`. This local configuration will be used to initialize the controller and the brain repository, similar to how `/packages/brainsOS/modules/llm-gateway/config` files initialize the LLM gateway. This will eventually be moved to a DynamoDB table but for now, we want to keep it simple and have the flexibility to change the configuration.

    **Completed:**
    - Created `BrainsRepository` with local storage implementation
    - Implemented `LocalLoader` for loading configurations from JSON
    - Set up proper directory structure with types and utils
    - Created `defaults.json` with brain configurations
    - Added interface for future DynamoDB integration
    - Implemented proper error handling and logging

- [x] We will follow the same pattern as the LLM gateway for type definitions, creating Request and Response types in `/packages/brainsOS/modules/controller/src/types/`:
    - `BrainRequest.ts`: Defines the interface for brain operations and includes validation
    - `BrainResponse.ts`: Defines the response structure for brain operations
    - `BrainConfig.ts`: Defines the configuration interface for brains

    **Completed:**
    - Created comprehensive type definitions
    - Added type guards for runtime validation
    - Implemented response factory functions
    - Added proper error handling types
    - Created configuration interfaces

- [x] The brain configuration will follow the structure defined in `defaults.json`, where each brain has:
    ```typescript
    {
        name: string;
        config: {
            modelId: string;
            provider: string;
            nickname: string;
            systemPrompt: string;
            persona: string;
        }
    }
    ```

    **Completed:**
    - Implemented configuration structure in `defaults.json`
    - Added validation for required fields
    - Created type definitions for configuration
    - Added support for multiple brain configurations
    - Implemented configuration loading and caching

- [x] The BrainController singleton will implement the following interface:
    ```typescript
    interface BrainController {
        initialize(): Promise<void>;
        getBrain(name: string): Promise<BrainConfig>;
        processRequest(request: BrainRequest): Promise<BrainResponse>;
        handleError(error: Error): BrainResponse;
    }
    ```

    **Completed:**
    - Implemented all required interface methods
    - Added additional functionality:
        - Conversation state management
        - MCP prompt integration
        - System prompt formatting
        - Error handling and logging
    - Added support for:
        - Multiple brain configurations
        - Configurable brain selection
        - Response formatting
        - Status tracking

**Additional Completed Features:**

1. **WebSocket Integration**
   - Created new handler in `/handlers/websocket/brain-controller/`
   - Maintained compatibility with existing message format
   - Added proper error handling and logging
   - Implemented message type conversion

2. **MCP Integration**
   - Added MCP prompt loading and formatting
   - Integrated MCP format into system prompts
   - Added support for structured responses
   - Implemented conversation context management

3. **Error Handling**
   - Added comprehensive error handling
   - Implemented proper error responses
   - Added logging for debugging
   - Created error type definitions

4. **Testing and Validation**
   - Added type guards for runtime validation
   - Implemented configuration validation
   - Added error handling for invalid states
   - Created response validation

**Future Enhancements:**

1. **DynamoDB Integration**
   - Implement persistent storage
   - Add configuration for table names
   - Add backup/restore functionality

2. **Additional Features**
   - Add brain versioning
   - Implement brain-specific validation rules
   - Add support for different brain modalities

3. **Monitoring and Metrics**
   - Add performance metrics collection
   - Implement health checks
   - Add usage statistics

4. **Security**
   - Add authentication for brain operations
   - Implement access control
   - Add encryption for sensitive configurations

### PROJECT 2

[ ] We currently have a simple MCP server working in `/packages/brainsOS/modules/mcp-server/`, but a few samples prompts, resources and tools. There is a basic pattern described in the base README.md file in `/packages/brainsOS/modules/mcp-server/core/built-in/`. These are trivial, demonstrative MCP implementations that should follow the MCP standard described in https://www.philschmid.de/mcp-example-llama and https://modelcontextprotocol.io/introduction. 

[ ] The MCP server needs to be accessible via a websocket channel, via a new handler in `/packages/brainsOS/handlers/websocket/mcp-server/mcp.ts`. We will want to follow our llm-gateway and controller pattern to create a singleton instance of the mcp server. 

[ ] We will create types for MCP requests and responses in `/packages/brainsOS/modules/mcp-server/src/types/`:
    - `MCPRequest.ts`: Defines the interface for MCP requests including validation
    - `MCPResponse.ts`: Defines the response structure for MCP operations
    - `MCPError.ts`: Defines error types and handling

[ ] We will configure timeouts in `/packages/brainsOS/modules/mcp-server/config/settings.json`:
    - Default timeout for all requests
    - Per-tool type timeouts
    - Retry configuration if needed

[ ] We will implement monitoring and logging:
    - Track request start time and completion
    - Log all MCP requests and responses
    - Implement error tracking for failed requests
    - Monitor for missing responses

[ ] The MCPServer singleton will implement the following interface:
    ```typescript
    interface MCPServer {
        initialize(): Promise<void>;
        processRequest(request: MCPRequest): Promise<MCPResponse>;
        getTool(toolName: string): Promise<MCPTool>;
        handleError(error: Error): MCPResponse;
    }
    ```

[ ] We should be able to send a MCP request to the MCP server via the websocket channel. 

    ```typescript
    const mcpServerWebSocketFunction = new sst.aws.Function("mcpServerWebSocketFunction", {
        handler: "packages/brainsOS/handlers/websocket/mcp-server/mcp.handler",
    });

    brainsOS_wss.route("mcp/request", mcpServerWebSocketFunction.arn); 
    ```

    and the handler will process messages like this:
    
    ```json
    {
        "action": "mcp/request", 
        "data": {
            "requestType": "tool", 
            "requestId": UUID, 
            "toolName": "randomNumber", 
            "parameters": {
                "min": 0, 
                "max": 100
            }
        }
    }
    ```

    and the tool will return a response like this:

    ```json
    {
        "action": "mcp/response", 
        "data": {
            "requestId": UUID, 
            "response": "23"
        }
    }
    ```

    Error handling will be implemented at the tool level, following the pattern in `randomNumber.ts` where:
    - Input validation is performed
    - Tool-specific errors are caught and formatted
    - Responses include success/failure status and metadata

### PROJECT 3

[ ] The controller is a key component of the system. It will receive requests from the terminal, and pass them to the LLM gateway. This already works. What we need to do after is leverage the MCP standard (see https://www.philschmid.de/mcp-example-llama and https://modelcontextprotocol.io/introduction ) to decompose queries from the terminal into MCP requests. As a first step, we will extract MCP requests from the terminal and paste them into the console to confirm this initial step works.

[ ] We will implement MCP request extraction using a specialized prompt that follows the MCP standard. The prompt will instruct the LLM to identify and format MCP requests in a specific way, similar to the example in the MCP documentation.

[ ] We will define message formats for the system:
    - Terminal messages (existing in messagesTypes.ts)
    - Status messages (new type)
    - Content messages (new type)
    - Error messages (existing in messagesTypes.ts)

    The status message format will be:
    ```typescript
    interface StatusMessage {
        type: 'status';
        data: {
            status: 'queued' | 'processing' | 'completed' | 'failed';
            requestId: string;
            timestamp: string;
            source: 'mcp';
            metadata?: Record<string, unknown>;
        }
    }
    ```

    The SQS message format will be:
    ```typescript
    interface SQSMessage {
        requestId: string;
        mcpRequest: MCPRequest;
        responseChannel: string;
        timestamp: string;
        metadata?: Record<string, unknown>;
    }
    ```

[ ] Once we know that each MCP request can be extracted reliably, we will break down each MCP request into a seperate message that will be sent into an SQS queue. Each MCP is a seperate message. The message needs to include the MCP request and the response channel.

[ ] When an MCP message is sent to the queue, we will send a status message to the terminal. This will be a new type of message that will transmit status information. The controller will be in charge of sending a status message when the message is sent to the queue, and when a response is received in the websocket channel.

[ ] We will create an event handler that takes messagse from the MCP queue, processes the request by calling the local MCP server, and then sending the message back to the websocket channel where the controller is listening. The handler will:
    - Forward messages to the MCP server singleton
    - Respect timeout values from the MCP server configuration
    - Handle errors and send appropriate status messages

[ ] When the websocket channel receives the response message from the SQS event handler, it will inject the response into the LLM message stream and reprocess the message via the LLM gateway. We will follow the MCP example pattern for injecting responses into the conversation, ensuring:
    - No loops are created in the conversation flow
    - Responses are properly formatted for the LLM gateway
    - The conversation context is maintained

## RESULTS

### Project 1: Brain Controller Implementation

#### Completed Features

1. **Module Structure**
   - Created `/modules/brain-controller/` with clear separation of concerns
   - Implemented repository, types, and utils directories
   - Moved logic from websocket handler to controller module

2. **Singleton Pattern**
   - Implemented `BrainController` as a singleton
   - Added proper initialization and error handling
   - Integrated with LLM Gateway singleton

3. **Repository Implementation**
   - Created `BrainsRepository` with local storage
   - Implemented interface for future DynamoDB support
   - Added configuration loading from `defaults.json`

4. **Type System**
   - Created comprehensive type definitions:
     - `BrainConfig`: Brain configuration structure
     - `BrainRequest`: Request validation and structure
     - `BrainResponse`: Response formatting and types
   - Added type guards for runtime validation

5. **WebSocket Integration**
   - Created new handler in `/handlers/websocket/brain-controller/`
   - Maintained compatibility with existing message format
   - Added proper error handling and logging

6. **Configuration Management**
   - Implemented local configuration loading
   - Added support for multiple brain configurations
   - Prepared for future DynamoDB integration

#### Future Enhancements

1. **DynamoDB Integration**
   - Implement persistent storage
   - Add configuration for table names
   - Add backup/restore functionality

2. **Additional Features**
   - Add brain versioning
   - Implement brain-specific validation rules
   - Add support for different brain modalities

3. **Monitoring and Metrics**
   - Add performance metrics collection
   - Implement health checks
   - Add usage statistics

4. **Security**
   - Add authentication for brain operations
   - Implement access control
   - Add encryption for sensitive configurations

